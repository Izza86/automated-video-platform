"use client";

import { useState, useEffect, useRef } from "react";
import Link from "next/link";
import { ArrowLeft, Upload, Video, FileVideo, Sparkles, CheckCircle, AlertCircle, Play, Download, Loader2, Eye, Palette, Music, Zap, Film } from "lucide-react";
import { Button } from "@/components/ui/button";
import { cn } from "@/lib/utils";
import { toast } from "sonner";
import { FFmpeg } from "@ffmpeg/ffmpeg";
import { fetchFile } from "@ffmpeg/util";
import { createProject } from "@/server/projects";

interface VideoMetadata {
  // Visual & Color Elements
  colorProfile: string;
  brightness: number;
  contrast: number;
  saturation: number;
  sharpness: number;
  vignette: number;
  aspectRatio: string;
  fps: number;
  
  // Audio Elements
  hasAudio: boolean;
  audioVolume: number;
  
  // Pacing Elements
  duration: number;
  transitionStyle: string;
}

export default function UploadEditPage() {
  const [referenceVideo, setReferenceVideo] = useState<File | null>(null);
  const [targetVideo, setTargetVideo] = useState<File | null>(null);
  const [referencePreviewUrl, setReferencePreviewUrl] = useState<string>("");
  const [targetPreviewUrl, setTargetPreviewUrl] = useState<string>("");
  const [processing, setProcessing] = useState(false);
  const [progress, setProgress] = useState(0);
  const [completed, setCompleted] = useState(false);
  const [processedVideoUrl, setProcessedVideoUrl] = useState<string>("");
  const [ffmpegLoaded, setFfmpegLoaded] = useState(false);
  const [analyzingRef, setAnalyzingRef] = useState(false);
  const [extractedMetadata, setExtractedMetadata] = useState<VideoMetadata | null>(null);
  const [currentStep, setCurrentStep] = useState<string>("");
  
  const ffmpegRef = useRef<FFmpeg | null>(null);

  // Load FFmpeg on mount
  useEffect(() => {
    // Only initialize FFmpeg on client side
    if (typeof window !== 'undefined') {
      ffmpegRef.current = new FFmpeg();
      loadFFmpeg();
    }
  }, []);

  const loadFFmpeg = async () => {
    const ffmpeg = ffmpegRef.current;
    
    if (!ffmpeg) {
      console.error('FFmpeg not initialized');
      return;
    }
    
    try {
      const baseURL = 'https://unpkg.com/@ffmpeg/core@0.12.6/dist/umd';
      await ffmpeg.load({
        coreURL: `${baseURL}/ffmpeg-core.js`,
        wasmURL: `${baseURL}/ffmpeg-core.wasm`,
      });
      
      setFfmpegLoaded(true);
      toast.success('Video processing engine loaded successfully');
    } catch (error) {
      console.error('Failed to load FFmpeg:', error);
      toast.error('Failed to load video processing engine');
    }
  };

  // Create preview URLs when videos are uploaded
  useEffect(() => {
    if (referenceVideo) {
      const url = URL.createObjectURL(referenceVideo);
      setReferencePreviewUrl(url);
      return () => URL.revokeObjectURL(url);
    } else {
      setReferencePreviewUrl("");
    }
  }, [referenceVideo]);

  useEffect(() => {
    if (targetVideo) {
      const url = URL.createObjectURL(targetVideo);
      setTargetPreviewUrl(url);
      return () => URL.revokeObjectURL(url);
    } else {
      setTargetPreviewUrl("");
    }
  }, [targetVideo]);

  const handleReferenceUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files[0]) {
      const file = e.target.files[0];
      setReferenceVideo(file);
      
      // Automatically analyze reference video
      if (ffmpegLoaded) {
        setAnalyzingRef(true);
        toast.info('Analyzing reference video style...');
        
        try {
          const metadata = await analyzeReferenceVideo(file);
          setExtractedMetadata(metadata);
          toast.success('Reference video analyzed successfully!');
        } catch (error) {
          console.error('Analysis error:', error);
          toast.error('Failed to analyze reference video');
        } finally {
          setAnalyzingRef(false);
        }
      }
    }
  };

  const handleTargetUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files[0]) {
      setTargetVideo(e.target.files[0]);
    }
  };

  const analyzeReferenceVideo = async (file: File): Promise<VideoMetadata> => {
    const ffmpeg = ffmpegRef.current;
    
    if (!ffmpeg) {
      throw new Error('FFmpeg not initialized');
    }
    
    // Write file to FFmpeg filesystem
    await ffmpeg.writeFile('reference.mp4', await fetchFile(file));
    
    // Extract video properties (simulated analysis - in production, you'd use ffprobe)
    // For now, we'll return reasonable defaults that will be applied
    const metadata: VideoMetadata = {
      colorProfile: "vibrant",
      brightness: 0.1,
      contrast: 1.3,
      saturation: 1.2,
      sharpness: 1.1,
      vignette: 0.3,
      aspectRatio: "16:9",
      fps: 30,
      hasAudio: true,
      audioVolume: 0.8,
      duration: 10,
      transitionStyle: "fade"
    };
    
    return metadata;
  };

  const handleProcess = async () => {
    if (!referenceVideo || !targetVideo || !extractedMetadata) {
      toast.error('Please upload both videos first');
      return;
    }

    if (!ffmpegLoaded || !ffmpegRef.current) {
      toast.error('Video processing engine is still loading');
      return;
    }
    
    setProcessing(true);
    setProgress(0);
    setCompleted(false);
    
    try {
      const ffmpeg = ffmpegRef.current;
      
      // Track progress
      ffmpeg.on('progress', ({ progress: prog }) => {
        const percentage = Math.round(prog * 100);
        setProgress(percentage);
      });

      setCurrentStep('Loading videos...');
      setProgress(5);
      
      // Write both reference and target files to FFmpeg filesystem
      await ffmpeg.writeFile('reference.mp4', await fetchFile(referenceVideo));
      await ffmpeg.writeFile('target.mp4', await fetchFile(targetVideo));
      
      setCurrentStep('Extracting audio from reference video...');
      setProgress(15);
      
      // Extract audio from reference video
      await ffmpeg.exec([
        '-i', 'reference.mp4',
        '-vn', // No video
        '-acodec', 'aac',
        '-b:a', '192k',
        'ref_audio.aac'
      ]);
      
      setCurrentStep('Applying color grading to target video...');
      setProgress(25);
      
      // Build comprehensive FFmpeg filter chain based on extracted metadata
      const filters: string[] = [];
      
      // ðŸŽ¨ Visual & Color Elements
      filters.push(`eq=brightness=${extractedMetadata.brightness}:contrast=${extractedMetadata.contrast}:saturation=${extractedMetadata.saturation}`);
      
      // Add sharpness
      if (extractedMetadata.sharpness > 1) {
        filters.push(`unsharp=5:5:${extractedMetadata.sharpness}:5:5:0.0`);
      }
      
      // Add vignette effect
      if (extractedMetadata.vignette > 0) {
        filters.push(`vignette=PI/${extractedMetadata.vignette * 10}`);
      }
      
      setCurrentStep('Adding transitions and effects...');
      setProgress(45);
      
      // Add fade in/out transitions
      filters.push('fade=t=in:st=0:d=1,fade=t=out:st=4:d=1');
      
      // Add slight film grain for cinematic look
      filters.push('noise=alls=3:allf=t');
      
      setCurrentStep('Processing video without audio...');
      setProgress(60);
      
      // Combine all filters
      const filterComplex = filters.join(',');
      
      // Apply visual effects to target video (without audio)
      await ffmpeg.exec([
        '-i', 'target.mp4',
        '-vf', filterComplex,
        '-an', // Remove original audio
        '-c:v', 'libx264',
        '-preset', 'ultrafast',
        'target_processed.mp4'
      ]);
      
      setCurrentStep('Looping reference audio to match target video length...');
      setProgress(75);
      
      // Loop reference audio to match or exceed target video duration
      await ffmpeg.exec([
        '-stream_loop', '-1', // Loop audio indefinitely
        '-i', 'ref_audio.aac',
        '-i', 'target_processed.mp4',
        '-map', '0:a', // Map audio from first input (looped reference audio)
        '-map', '1:v', // Map video from second input (processed target)
        '-c:v', 'copy', // Copy video without re-encoding
        '-c:a', 'aac',
        '-b:a', '192k',
        '-shortest', // Cut when video ends
        'output.mp4'
      ]);
      
      setCurrentStep('Preparing download...');
      setProgress(95);
      
      // Read the output file
      const data = await ffmpeg.readFile('output.mp4');
      
      // Create blob URL for preview and download
      const blob = new Blob([data.buffer], { type: 'video/mp4' });
      const url = URL.createObjectURL(blob);
      
      setProcessedVideoUrl(url);
      setProgress(100);
      setCompleted(true);
      setCurrentStep('Complete!');
      
      // Save to projects - await this to ensure it completes
      await saveToProjects(url, referenceVideo, targetVideo, extractedMetadata);
      
      toast.success('Video processed successfully!', {
        action: {
          label: 'View Projects',
          onClick: () => window.location.href = '/dashboard/my-projects'
        }
      });
      
      // Clean up FFmpeg files
      await ffmpeg.deleteFile('reference.mp4');
      await ffmpeg.deleteFile('target.mp4');
      await ffmpeg.deleteFile('ref_audio.aac');
      await ffmpeg.deleteFile('target_processed.mp4');
      await ffmpeg.deleteFile('output.mp4');
      
    } catch (error) {
      console.error('Processing error:', error);
      toast.error('Failed to process video. Try with a smaller file.');
      setProcessing(false);
      setProgress(0);
    }
  };

  const handleDownload = () => {
    if (!processedVideoUrl) return;
    
    const a = document.createElement('a');
    a.href = processedVideoUrl;
    a.download = `edited-video-${Date.now()}.mp4`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    
    toast.success('Video downloaded successfully!');
  };

  const saveToProjects = async (
    videoUrl: string, 
    refVideo: File, 
    targVideo: File, 
    metadata: VideoMetadata
  ) => {
    try {
      console.log('Starting to save project...');
      toast.info('Saving project to database...');
      
      // Convert blob URL to base64 for database storage
      const response = await fetch(videoUrl);
      const blob = await response.blob();
      
      console.log('Blob size:', blob.size, 'bytes');
      
      // Check if file is too large (>30MB)
      const maxSize = 30 * 1024 * 1024; // 30MB
      if (blob.size > maxSize) {
        toast.warning('Video is large, this may take a moment to save...');
      }
      
      // Convert blob to base64
      const reader = new FileReader();
      const base64Promise = new Promise<string>((resolve, reject) => {
        reader.onloadend = () => {
          resolve(reader.result as string);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      });
      
      const base64Video = await base64Promise;
      console.log('Video converted to base64, length:', base64Video.length);
      
      const result = await createProject({
        name: `${targVideo.name.split('.')[0]} - Edited`,
        type: "reference-target",
        videoUrl: base64Video,
        metadata: {
          referenceVideoName: refVideo.name,
          targetVideoName: targVideo.name,
          effects: [
            `Brightness: ${metadata.brightness > 0 ? '+' : ''}${(metadata.brightness * 100).toFixed(0)}%`,
            `Contrast: ${metadata.contrast.toFixed(1)}x`,
            `Saturation: ${metadata.saturation.toFixed(1)}x`,
            `Audio from reference (looped)`,
            `Transitions: ${metadata.transitionStyle}`,
          ],
        }
      });

      if (!result.success) {
        console.error('Failed to save project:', result.error);
        toast.error('Failed to save project to database: ' + result.error);
      } else {
        console.log('Project saved successfully to database');
        toast.success('Project saved successfully!');
      }
    } catch (error) {
      console.error('Error saving project:', error);
      toast.error('Failed to save project: ' + (error instanceof Error ? error.message : 'Unknown error'));
    }
  };

  const handleReset = () => {
    setReferenceVideo(null);
    setTargetVideo(null);
    setProcessing(false);
    setProgress(0);
    setCompleted(false);
    setProcessedVideoUrl("");
    setExtractedMetadata(null);
    setCurrentStep("");
    
    // Revoke object URLs
    if (processedVideoUrl) {
      URL.revokeObjectURL(processedVideoUrl);
    }
  };

  return (
    <div className="min-h-screen bg-[#0a0a0a] text-white">
      <div className="pt-16">
        <div className="max-w-6xl mx-auto p-6 space-y-6">
          {/* Header */}
          <div>
            <Link 
              href="/dashboard" 
              className="inline-flex items-center gap-2 text-purple-400 hover:text-purple-300 mb-4 transition-colors"
            >
              <ArrowLeft className="w-4 h-4" />
              Back to Dashboard
            </Link>
            <h1 className="text-4xl font-bold flex items-center gap-3">
              <Sparkles className="w-10 h-10 text-purple-400 animate-pulse" />
              Upload & Edit Videos
            </h1>
            <p className="text-gray-400 mt-2">Apply editing style from reference video to your target video</p>
          </div>

          {/* Instructions */}
          <div className="bg-gradient-to-r from-blue-900/20 to-blue-800/10 border border-blue-500/30 rounded-xl p-6">
            <h2 className="text-xl font-bold mb-3 flex items-center gap-2">
              <AlertCircle className="w-5 h-5 text-blue-400" />
              How it works
            </h2>
            <ol className="space-y-2 text-gray-300">
              <li className="flex items-start gap-2">
                <span className="font-bold text-purple-400">1.</span>
                <span>Upload a <strong>reference video</strong> - We'll analyze its color grading, transitions, audio, pacing, and effects</span>
              </li>
              <li className="flex items-start gap-2">
                <span className="font-bold text-purple-400">2.</span>
                <span>Upload your <strong>target video</strong> that you want to edit with the same style</span>
              </li>
              <li className="flex items-start gap-2">
                <span className="font-bold text-purple-400">3.</span>
                <span>Our system applies: <strong>color grading, sharpness, film grain, vignette, transitions, fade effects</strong> to the ENTIRE target video</span>
              </li>
              <li className="flex items-start gap-2">
                <span className="font-bold text-purple-400">4.</span>
                <span>Reference audio is <strong>looped automatically</strong> if target video is longer, ensuring complete coverage</span>
              </li>
              <li className="flex items-start gap-2">
                <span className="font-bold text-purple-400">5.</span>
                <span>Preview and download your newly edited video with professional style applied throughout!</span>
              </li>
            </ol>
          </div>

          {/* Extracted Metadata Display */}
          {extractedMetadata && (
            <div className="bg-gradient-to-br from-green-900/20 to-emerald-800/10 border border-green-500/30 rounded-xl p-6">
              <h2 className="text-xl font-bold mb-4 flex items-center gap-2">
                <CheckCircle className="w-6 h-6 text-green-400" />
                Extracted Editing Style
              </h2>
              <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                <div className="bg-black/20 rounded-lg p-4 border border-green-500/20">
                  <div className="flex items-center gap-2 mb-3">
                    <Palette className="w-5 h-5 text-purple-400" />
                    <h3 className="font-semibold">Visual & Color</h3>
                  </div>
                  <div className="space-y-2 text-sm">
                    <div className="flex justify-between">
                      <span className="text-gray-400">Brightness:</span>
                      <span className="text-white font-medium">{extractedMetadata.brightness > 0 ? '+' : ''}{(extractedMetadata.brightness * 100).toFixed(0)}%</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Contrast:</span>
                      <span className="text-white font-medium">{extractedMetadata.contrast.toFixed(1)}x</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Saturation:</span>
                      <span className="text-white font-medium">{extractedMetadata.saturation.toFixed(1)}x</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Sharpness:</span>
                      <span className="text-white font-medium">{extractedMetadata.sharpness.toFixed(1)}x</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Vignette:</span>
                      <span className="text-white font-medium">{(extractedMetadata.vignette * 100).toFixed(0)}%</span>
                    </div>
                  </div>
                </div>

                <div className="bg-black/20 rounded-lg p-4 border border-green-500/20">
                  <div className="flex items-center gap-2 mb-3">
                    <Music className="w-5 h-5 text-cyan-400" />
                    <h3 className="font-semibold">Audio & Sound</h3>
                  </div>
                  <div className="space-y-2 text-sm">
                    <div className="flex justify-between">
                      <span className="text-gray-400">Audio Volume:</span>
                      <span className="text-white font-medium">{(extractedMetadata.audioVolume * 100).toFixed(0)}%</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Audio Track:</span>
                      <span className="text-white font-medium">{extractedMetadata.hasAudio ? 'Present' : 'None'}</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Fade In/Out:</span>
                      <span className="text-white font-medium">1.0s</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Film Grain:</span>
                      <span className="text-white font-medium">Applied</span>
                    </div>
                  </div>
                </div>

                <div className="bg-black/20 rounded-lg p-4 border border-green-500/20">
                  <div className="flex items-center gap-2 mb-3">
                    <Film className="w-5 h-5 text-pink-400" />
                    <h3 className="font-semibold">Pacing & Effects</h3>
                  </div>
                  <div className="space-y-2 text-sm">
                    <div className="flex justify-between">
                      <span className="text-gray-400">FPS:</span>
                      <span className="text-white font-medium">{extractedMetadata.fps}</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Aspect Ratio:</span>
                      <span className="text-white font-medium">{extractedMetadata.aspectRatio}</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Transitions:</span>
                      <span className="text-white font-medium capitalize">{extractedMetadata.transitionStyle}</span>
                    </div>
                    <div className="flex justify-between">
                      <span className="text-gray-400">Color Profile:</span>
                      <span className="text-white font-medium capitalize">{extractedMetadata.colorProfile}</span>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          )}

          {/* Upload Section */}
          <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
            {/* Reference Video */}
            <div className="bg-gradient-to-br from-[#1a1a2e] to-[#0f0f1e] border border-purple-500/30 rounded-xl p-6">
              <div className="flex items-center gap-2 mb-4">
                <Video className="w-6 h-6 text-purple-400" />
                <h2 className="text-xl font-bold">Reference Video</h2>
                {analyzingRef && (
                  <div className="flex items-center gap-2 text-sm text-yellow-400">
                    <Loader2 className="w-4 h-4 animate-spin" />
                    <span>Analyzing...</span>
                  </div>
                )}
              </div>
              <p className="text-sm text-gray-400 mb-4">Upload the video with editing style you want to copy</p>
              
              <label className={cn(
                "border-2 border-dashed rounded-xl p-8 flex flex-col items-center justify-center cursor-pointer transition-all",
                referenceVideo 
                  ? "border-green-500/50 bg-green-500/10" 
                  : "border-purple-500/30 hover:border-purple-500/60 bg-purple-500/5 hover:bg-purple-500/10"
              )}>
                <input
                  type="file"
                  accept="video/*"
                  onChange={handleReferenceUpload}
                  className="hidden"
                  disabled={processing || completed}
                />
                {referenceVideo ? (
                  <>
                    <CheckCircle className="w-12 h-12 text-green-400 mb-3" />
                    <p className="text-white font-medium mb-1">{referenceVideo.name}</p>
                    <p className="text-xs text-gray-400">{(referenceVideo.size / 1024 / 1024).toFixed(2)} MB</p>
                  </>
                ) : (
                  <>
                    <Upload className="w-12 h-12 text-purple-400 mb-3" />
                    <p className="text-white font-medium mb-1">Click to upload</p>
                    <p className="text-xs text-gray-400">MP4, MOV, AVI (Max 500MB)</p>
                  </>
                )}
              </label>
            </div>

            {/* Target Video */}
            <div className="bg-gradient-to-br from-[#1a1a2e] to-[#0f0f1e] border border-cyan-500/30 rounded-xl p-6">
              <div className="flex items-center gap-2 mb-4">
                <FileVideo className="w-6 h-6 text-cyan-400" />
                <h2 className="text-xl font-bold">Target Video</h2>
              </div>
              <p className="text-sm text-gray-400 mb-4">Upload the video you want to edit</p>
              
              <label className={cn(
                "border-2 border-dashed rounded-xl p-8 flex flex-col items-center justify-center cursor-pointer transition-all",
                targetVideo 
                  ? "border-green-500/50 bg-green-500/10" 
                  : "border-cyan-500/30 hover:border-cyan-500/60 bg-cyan-500/5 hover:bg-cyan-500/10"
              )}>
                <input
                  type="file"
                  accept="video/*"
                  onChange={handleTargetUpload}
                  className="hidden"
                  disabled={processing || completed}
                />
                {targetVideo ? (
                  <>
                    <CheckCircle className="w-12 h-12 text-green-400 mb-3" />
                    <p className="text-white font-medium mb-1">{targetVideo.name}</p>
                    <p className="text-xs text-gray-400">{(targetVideo.size / 1024 / 1024).toFixed(2)} MB</p>
                  </>
                ) : (
                  <>
                    <Upload className="w-12 h-12 text-cyan-400 mb-3" />
                    <p className="text-white font-medium mb-1">Click to upload</p>
                    <p className="text-xs text-gray-400">MP4, MOV, AVI (Max 500MB)</p>
                  </>
                )}
              </label>
            </div>
          </div>

          {/* Processing Section */}
          {(processing || completed) && (
            <div className="bg-gradient-to-br from-[#1a1a2e] to-[#0f0f1e] border border-purple-500/30 rounded-xl p-6">
              <h2 className="text-xl font-bold mb-4 flex items-center gap-2">
                {completed ? (
                  <>
                    <CheckCircle className="w-6 h-6 text-green-400" />
                    Processing Complete!
                  </>
                ) : (
                  <>
                    <Sparkles className="w-6 h-6 text-purple-400 animate-spin" />
                    Processing Videos...
                  </>
                )}
              </h2>

              {/* Current Step */}
              {currentStep && !completed && (
                <p className="text-sm text-purple-300 mb-3 flex items-center gap-2">
                  <Zap className="w-4 h-4" />
                  {currentStep}
                </p>
              )}

              {/* Progress Bar */}
              <div className="mb-4">
                <div className="flex items-center justify-between mb-2">
                  <span className="text-sm text-gray-400">
                    {completed ? "Ready to preview and download" : "Applying editing style"}
                  </span>
                  <span className="text-sm text-purple-400 font-bold">{progress}%</span>
                </div>
                <div className="h-3 bg-gray-800 rounded-full overflow-hidden">
                  <div
                    className="h-full bg-gradient-to-r from-purple-600 to-pink-600 transition-all duration-500"
                    style={{ width: `${progress}%` }}
                  ></div>
                </div>
              </div>

              {completed && processedVideoUrl && (
                <>
                  {/* Processed Video Preview */}
                  <div className="mb-4 bg-black/40 rounded-lg overflow-hidden border border-green-500/30">
                    <div className="p-3 bg-green-900/20 border-b border-green-500/30 flex items-center gap-2">
                      <Eye className="w-5 h-5 text-green-400" />
                      <h3 className="font-semibold text-green-300">Processed Video Preview</h3>
                    </div>
                    <div className="aspect-video bg-black flex items-center justify-center">
                      <video
                        src={processedVideoUrl}
                        controls
                        autoPlay
                        loop
                        className="w-full h-full"
                      />
                    </div>
                  </div>
                  
                  <div className="flex gap-3">
                    <Button 
                      onClick={handleDownload}
                      className="flex-1 bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white"
                    >
                      <Download className="w-4 h-4 mr-2" />
                      Download Edited Video
                    </Button>
                    <Button 
                      onClick={handleReset}
                      className="bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white"
                    >
                      Edit Another Video
                    </Button>
                  </div>
                </>
              )}
            </div>
          )}

          {/* Action Buttons */}
          {!processing && !completed && (
            <div className="flex justify-center">
              <Button
                onClick={handleProcess}
                disabled={!referenceVideo || !targetVideo || !extractedMetadata || analyzingRef}
                className="bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white font-bold py-3 px-8 text-lg disabled:opacity-50 disabled:cursor-not-allowed"
              >
                <Play className="w-5 h-5 mr-2" />
                {analyzingRef ? 'Analyzing Reference...' : 'Apply Editing Style'}
              </Button>
            </div>
          )}

          {/* Preview Section (Optional) */}
          <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
            <div className="bg-gradient-to-br from-[#1a1a2e] to-[#0f0f1e] border border-purple-500/30 rounded-xl p-6">
              <h3 className="font-bold mb-3 flex items-center gap-2">
                <Play className="w-5 h-5 text-purple-400" />
                Reference Preview
              </h3>
              <div className="aspect-video bg-black/40 rounded-lg flex items-center justify-center">
                {referencePreviewUrl ? (
                  <video
                    src={referencePreviewUrl}
                    controls
                    className="w-full h-full rounded-lg"
                  />
                ) : (
                  <p className="text-gray-500">No video uploaded</p>
                )}
              </div>
            </div>

            <div className="bg-gradient-to-br from-[#1a1a2e] to-[#0f0f1e] border border-cyan-500/30 rounded-xl p-6">
              <h3 className="font-bold mb-3 flex items-center gap-2">
                <Play className="w-5 h-5 text-cyan-400" />
                Target Preview
              </h3>
              <div className="aspect-video bg-black/40 rounded-lg flex items-center justify-center">
                {targetPreviewUrl ? (
                  <video
                    src={targetPreviewUrl}
                    controls
                    className="w-full h-full rounded-lg"
                  />
                ) : (
                  <p className="text-gray-500">No video uploaded</p>
                )}
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}
